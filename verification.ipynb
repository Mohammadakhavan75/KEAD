{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot imgs or feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "idx=0\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 5))  # Adjust figsize as needed\n",
    "\n",
    "# Display the first image\n",
    "ax1.imshow(cv2.resize(imgs[idx].permute(1,2,0).detach().cpu().numpy(), (128, 128)))\n",
    "ax1.set_title('Image 1')\n",
    "ax1.axis('off')  # Turn off axes for cleaner presentation (optional)\n",
    "\n",
    "# Display the second image\n",
    "ax2.imshow(cv2.resize(positive_imgs[idx].permute(1,2,0).detach().cpu().numpy(), (128, 128)))\n",
    "ax2.set_title('Image 2')\n",
    "ax2.axis('off')  # Turn off axes (optional)\n",
    "\n",
    "ax3.imshow(cv2.resize(negative_imgs[idx].permute(1,2,0).detach().cpu().numpy(), (128, 128)))\n",
    "ax3.set_title('Image 3')\n",
    "ax3.axis('off')  # Turn off axes (optional)\n",
    "\n",
    "# Adjust spacing between subplots (optional)\n",
    "plt.subplots_adjust(left=0.05, right=0.95, wspace=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define a list to store the dataframes\n",
    "all_dfs = []\n",
    "\n",
    "# Loop through the CSV files and read them into dataframes\n",
    "for filename in os.listdir('./csv_results/report_class_1/'):  # Replace with your filenames\n",
    "  df = pd.read_csv(filename)\n",
    "  all_dfs.append(df)\n",
    "\n",
    "# Combine all dataframes vertically (stacking rows)\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)  # Optional: reset index\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "combined_df.to_csv(\"combined.csv\", index=False)  # Optional: remove index column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "all_dfs = []\n",
    "names= []\n",
    "root='./csv_results/report_class_1/'\n",
    "for filename in os.listdir(root):\n",
    "    print(filename)\n",
    "    df = pd.read_csv(root + filename)\n",
    "    df.insert(loc=0, column='noise', value=filename.split('.')[0])\n",
    "    all_dfs.append(df)\n",
    "    names.append(filename.split('.')[0])\n",
    "\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df.to_csv(root + \"combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create all diffs pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "dataset = 'cifar10'\n",
    "\n",
    "softmax_sorted = {}\n",
    "diff_vals = {}\n",
    "for class_idx in range(10):\n",
    "    diff_vals[class_idx] = {}\n",
    "\n",
    "targets_list_loaded = np.load('/storage/users/makhavan/CSI/finals/datasets/generalization_repo_dataset/manual/CIFAR-10-Train-R-A/labels-A.npy')\n",
    "for class_idx in range(10):\n",
    "    indices = [k for k in range(len(targets_list_loaded)) if targets_list_loaded[k]==class_idx]\n",
    "    for file_name in os.listdir('./clip_vec/tensors/'):\n",
    "        if dataset in file_name and 'target' not in file_name and 'normal_data' not in file_name:\n",
    "            with open('./clip_vec/tensors/' + file_name, 'rb') as file:\n",
    "                diffs_loaded = pickle.load(file)\n",
    "        \n",
    "            noise_name = file_name.replace(f\"{dataset}_diffs_\", \"\", 1).split('.')[0]\n",
    "            diff_vals[class_idx][noise_name] = torch.mean(torch.tensor([diffs_loaded[idx].astype(np.float32) for idx in indices])).float()\n",
    "\n",
    "for i in range(10):\n",
    "    softmaxes = torch.nn.functional.softmax(torch.tensor(list(diff_vals[i].values())), dim=0).numpy()\n",
    "    for j, key in enumerate(diff_vals[i].keys()):\n",
    "        diff_vals[i][key] = softmaxes[j]\n",
    "\n",
    "for i in range(10):\n",
    "    sorted_values = sorted(diff_vals[i].items(), key=lambda item: item[1])\n",
    "    diff_vals[i] = dict(sorted_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "dataset = 'svhn'\n",
    "\n",
    "softmax_sorted = {}\n",
    "diff_vals = {}\n",
    "for class_idx in range(10):\n",
    "    diff_vals[class_idx] = {}\n",
    "\n",
    "targets_list_loaded = np.load('/storage/users/makhavan/CSI/finals/datasets/generalization_repo_dataset/manual/SVHN-Train-R-A/labels-A.npy')\n",
    "for class_idx in range(10):\n",
    "    indices = [k for k in range(len(targets_list_loaded)) if targets_list_loaded[k]==class_idx]\n",
    "    for file_name in os.listdir('./clip_vec/tensors/'):\n",
    "        if dataset in file_name and 'target' not in file_name and 'normal_data' not in file_name:\n",
    "            with open('./clip_vec/tensors/' + file_name, 'rb') as file:\n",
    "                diffs_loaded = pickle.load(file)\n",
    "        \n",
    "            noise_name = file_name.replace(f\"{dataset}_diffs_\", \"\", 1).split('.')[0]\n",
    "            diff_vals[class_idx][noise_name] = torch.mean(torch.tensor([diffs_loaded[idx].astype(np.float32) for idx in indices])).float()\n",
    "\n",
    "for i in range(10):\n",
    "    softmaxes = torch.nn.functional.softmax(torch.tensor(list(diff_vals[i].values())), dim=0).numpy()\n",
    "    for j, key in enumerate(diff_vals[i].keys()):\n",
    "        diff_vals[i][key] = softmaxes[j]\n",
    "\n",
    "for i in range(10):\n",
    "    sorted_values = sorted(diff_vals[i].items(), key=lambda item: item[1])\n",
    "    diff_vals[i] = dict(sorted_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n",
      "cifar100_diffs_rot90.pkl\n",
      "cifar100_diffs_random_crop.pkl\n",
      "cifar100_diffs_jpeg_compression.pkl\n",
      "cifar100_diffs_gaussian_noise.pkl\n",
      "cifar100_diffs_glass_blur.pkl\n",
      "cifar100_diffs_flip.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "CIFAR100_SUPERCLASS = [\n",
    "        [4, 31, 55, 72, 95],\n",
    "        [1, 33, 67, 73, 91],\n",
    "        [54, 62, 70, 82, 92],\n",
    "        [9, 10, 16, 29, 61],\n",
    "        [0, 51, 53, 57, 83],\n",
    "        [22, 25, 40, 86, 87],\n",
    "        [5, 20, 26, 84, 94],\n",
    "        [6, 7, 14, 18, 24],\n",
    "        [3, 42, 43, 88, 97],\n",
    "        [12, 17, 38, 68, 76],\n",
    "        [23, 34, 49, 60, 71],\n",
    "        [15, 19, 21, 32, 39],\n",
    "        [35, 63, 64, 66, 75],\n",
    "        [27, 45, 77, 79, 99],\n",
    "        [2, 11, 36, 46, 98],\n",
    "        [28, 30, 44, 78, 93],\n",
    "        [37, 50, 65, 74, 80],\n",
    "        [47, 52, 56, 59, 96],\n",
    "        [8, 13, 48, 58, 90],\n",
    "        [41, 69, 81, 85, 89],\n",
    "    ]\n",
    "\n",
    "dataset = 'cifar100'\n",
    "\n",
    "softmax_sorted = {}\n",
    "diff_vals = {}\n",
    "for class_idx in range(20):\n",
    "    diff_vals[class_idx] = {}\n",
    "\n",
    "targets_list_loaded = np.load('/storage/users/makhavan/CSI/finals/datasets/generalization_repo_dataset/CIFAR100_Train_AC/labels_train.npy')\n",
    "for class_idx in range(20):\n",
    "    indices = [k for k in range(len(targets_list_loaded)) if targets_list_loaded[k] in CIFAR100_SUPERCLASS[class_idx]]\n",
    "    for file_name in os.listdir('./clip_vec/tensors_selection/'):\n",
    "        if dataset in file_name and 'target' not in file_name and 'normal_data' not in file_name:\n",
    "            print(file_name)\n",
    "            with open('./clip_vec/tensors_selection/' + file_name, 'rb') as file:\n",
    "                diffs_loaded = pickle.load(file)\n",
    "        \n",
    "            noise_name = file_name.replace(f\"{dataset}_diffs_\", \"\", 1).split('.')[0]\n",
    "            diff_vals[class_idx][noise_name] = torch.mean(torch.tensor([diffs_loaded[idx].astype(np.float32) for idx in indices])).float()\n",
    "\n",
    "for i in range(20):\n",
    "    softmaxes = torch.nn.functional.softmax(torch.tensor(list(diff_vals[i].values())), dim=0).numpy()\n",
    "    for j, key in enumerate(diff_vals[i].keys()):\n",
    "        diff_vals[i][key] = softmaxes[j]\n",
    "\n",
    "for i in range(20):\n",
    "    sorted_values = sorted(diff_vals[i].items(), key=lambda item: item[1])\n",
    "    diff_vals[i] = dict(sorted_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ranks/selected_noises_cifar100_softmaxed.pkl', 'wb') as f:\n",
    "    pickle.dump(diff_vals, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfs = []\n",
    "for i in range(10):\n",
    "    pd.DataFrame(diff_vals[i], index=[i]).T.to_csv(f'{i}.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from clip import clip\n",
    "from torchvision.datasets import CIFAR10, SVHN\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import pickle\n",
    "from contrastive import cosine_similarity\n",
    "\n",
    "class load_np_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs_path, targets_path, transform):\n",
    "        self.data = np.load(imgs_path)\n",
    "        self.targets = np.load(targets_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img , target = self.data[idx], self.targets[idx]\n",
    "            \n",
    "        img = PIL.Image.fromarray(img)\n",
    "        if transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "\n",
    "cifar10_path = '/storage/users/makhavan/CSI/finals/datasets/data/'\n",
    "noises_root = '/storage/users/makhavan/CSI/finals/datasets/generalization_repo_dataset/CIFAR10_Train_AC/'\n",
    "cifar_train_cor_target_path = '/storage/users/makhavan/CSI/finals/datasets/generalization_repo_dataset/CIFAR10_Train_AC/labels_train.npy'\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "noraml_dataset = CIFAR10(root=cifar10_path, train=True, download=True, transform=transform)\n",
    "normal_loader = DataLoader(noraml_dataset, shuffle=False, batch_size=1)\n",
    "\n",
    "noise_loaders = {}\n",
    "for noise in os.listdir(noises_root):\n",
    "    if noise == 'labels_train.npy':\n",
    "        continue\n",
    "    else:\n",
    "        cifar_train_cor_img_path = noises_root + noise\n",
    "        aug_dataset = load_np_dataset(cifar_train_cor_img_path, cifar_train_cor_target_path, transform=transform)\n",
    "        noise_loaders[noise.split('.')[0]] = DataLoader(aug_dataset, shuffle=False, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "cosine_values = {}\n",
    "for key in noise_loaders.keys():\n",
    "    cosine_values[key] = []\n",
    "\n",
    "for key in noise_loaders.keys():\n",
    "    target_list = []\n",
    "    for normal_data, noise_data in zip(normal_loader, noise_loaders[key]):\n",
    "        normal_img, target = normal_data\n",
    "        noise_img, _ = noise_data\n",
    "        target_list.append(target)\n",
    "\n",
    "        cosine_values[key].append(cosine_similarity(normal_img, noise_img).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dataset='cifar10'\n",
    "with open(f'./{dataset}_cosine_softmaxed.pkl', 'rb') as file:\n",
    "    cosine_values = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "softmax_sorted = {}\n",
    "diff_vals = {}\n",
    "for class_idx in range(10):\n",
    "    diff_vals[class_idx] = {}\n",
    "\n",
    "for class_idx in range(10):\n",
    "    indices = [k for k in range(len(target_list)) if target_list[k]==class_idx]\n",
    "    for key in cosine_values.keys(): \n",
    "        # diff_vals[class_idx][key] = np.mean([cosine_values[key][idx].astype(np.float32) for idx in indices])\n",
    "        diff_vals[class_idx][key] = [cosine_values[key][idx].astype(np.float32) for idx in indices]\n",
    "\n",
    "for i in range(10):\n",
    "    softmaxes = torch.nn.functional.softmax(torch.tensor(list(diff_vals[i].values())), dim=0).numpy()\n",
    "    for j, key in enumerate(diff_vals[i].keys()):\n",
    "        diff_vals[i][key] = softmaxes[j]\n",
    "\n",
    "for i in range(10):\n",
    "    sorted_values = sorted(diff_vals[i].items(), key=lambda item: item[1], reverse=True)\n",
    "    diff_vals[i] = dict(sorted_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 7 Augmentation Image from single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader import load_cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from skimage.filters import gaussian\n",
    "from io import BytesIO\n",
    "from wand.image import Image as WandImage\n",
    "from scipy.ndimage import zoom as scizoom\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from wand.api import library as wandlibrary\n",
    "\n",
    "class MotionImage(WandImage):\n",
    "    def motion_blur(self, radius=0.0, sigma=0.0, angle=0.0):\n",
    "        wandlibrary.MagickMotionBlurImage(self.wand, radius, sigma, angle)\n",
    "\n",
    "def rot90(img):\n",
    "    rotater = transforms.RandomRotation(degrees=(270, 270))\n",
    "    return rotater(img)\n",
    "\n",
    "\n",
    "def flip(img):\n",
    "    hflipper = transforms.RandomHorizontalFlip(p=1.0)\n",
    "    return hflipper(img)\n",
    "\n",
    "\n",
    "def random_crop(img):\n",
    "    resize_cropper = transforms.RandomCrop(size=(480, 480)) # (32, 32)\n",
    "    resized = transforms.Resize(size=512)(resize_cropper(img))\n",
    "    return resized\n",
    "\n",
    "\n",
    "def gaussian_noise(x, severity=1):\n",
    "    c = [0.04, 0.06, .08, .09, .10][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    return np.clip(x + np.random.normal(size=x.shape, scale=c), 0, 1) * 255\n",
    "\n",
    "\n",
    "def glass_blur(x, severity=1):\n",
    "    # sigma, max_delta, iterations\n",
    "    c = [(0.05,1,1), (0.25,1,1), (0.4,1,1), (0.25,1,2), (0.4,1,2)][severity - 1]\n",
    "\n",
    "    x = np.uint8(gaussian(np.array(x) / 255., sigma=c[0], multichannel=True) * 255)\n",
    "\n",
    "    # locally shuffle pixels\n",
    "    for i in range(c[2]):\n",
    "        for h in range(512 - c[1], c[1], -1):\n",
    "            for w in range(512 - c[1], c[1], -1):\n",
    "                dx, dy = np.random.randint(-c[1], c[1], size=(2,))\n",
    "                h_prime, w_prime = h + dy, w + dx\n",
    "                # swap\n",
    "                x[h, w], x[h_prime, w_prime] = x[h_prime, w_prime], x[h, w]\n",
    "\n",
    "    return np.clip(gaussian(x / 255., sigma=c[0], multichannel=True), 0, 1) * 255\n",
    "\n",
    "\n",
    "def jpeg_compression(x, severity=1):\n",
    "    c = [80, 65, 58, 50, 40][severity - 1]\n",
    "\n",
    "    output = BytesIO()\n",
    "    x.save(output, 'JPEG', quality=c)\n",
    "    x = Image.open(output)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def clipped_zoom(img, zoom_factor):\n",
    "    h = img.shape[0]\n",
    "    # ceil crop height(= crop width)\n",
    "    ch = int(np.ceil(h / zoom_factor))\n",
    "\n",
    "    top = (h - ch) // 2\n",
    "    img = scizoom(img[top:top + ch, top:top + ch], (zoom_factor, zoom_factor, 1), order=1)\n",
    "    # trim off any extra pixels\n",
    "    trim_top = (img.shape[0] - h) // 2\n",
    "\n",
    "    return img[trim_top:trim_top + h, trim_top:trim_top + h]\n",
    "\n",
    "\n",
    "def snow(x, severity=1):\n",
    "    c = [(0.1,0.2,1,0.6,8,3,0.95),\n",
    "         (0.1,0.2,1,0.5,10,4,0.9),\n",
    "         (0.15,0.3,1.75,0.55,10,4,0.9),\n",
    "         (0.25,0.3,2.25,0.6,12,6,0.85),\n",
    "         (0.3,0.3,1.25,0.65,14,12,0.8)][severity - 1]\n",
    "\n",
    "    x = np.array(x, dtype=np.float32) / 255.\n",
    "    snow_layer = np.random.normal(size=x.shape[:2], loc=c[0], scale=c[1])  # [:2] for monochrome\n",
    "\n",
    "    snow_layer = clipped_zoom(snow_layer[..., np.newaxis], c[2])\n",
    "    snow_layer[snow_layer < c[3]] = 0\n",
    "\n",
    "    snow_layer = Image.fromarray((np.clip(snow_layer.squeeze(), 0, 1) * 255).astype(np.uint8), mode='L')\n",
    "    output = BytesIO()\n",
    "    snow_layer.save(output, format='PNG')\n",
    "    snow_layer = MotionImage(blob=output.getvalue())\n",
    "\n",
    "    snow_layer.motion_blur(radius=c[4], sigma=c[5], angle=np.random.uniform(-135, -45))\n",
    "\n",
    "    snow_layer = cv2.imdecode(np.fromstring(snow_layer.make_blob(), np.uint8),\n",
    "                              cv2.IMREAD_UNCHANGED) / 255.\n",
    "    snow_layer = snow_layer[..., np.newaxis]\n",
    "\n",
    "    x = c[6] * x + (1 - c[6]) * np.maximum(x, cv2.cvtColor(x, cv2.COLOR_RGB2GRAY).reshape(512, 512, 1) * 1.5 + 0.5)\n",
    "    return np.clip(x + snow_layer + np.rot90(snow_layer, k=2), 0, 1) * 255\n",
    "\n",
    "\n",
    "noises_list = ['rot90', 'flip', 'random_crop', 'gaussian_noise', 'glass_blur', 'jpeg_compression', 'snow']\n",
    "transform = transforms.ToTensor()\n",
    "img = transform((cv2.resize(cv2.imread('./figures/airplain_img/airplain.jpg'), (512, 512))))\n",
    "cv2.imwrite('./figures/car_img/car.jpg', (cv2.resize(cv2.imread('./figures/car_img/car.jpg'), (512, 512))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('./figures/airplain_img/rot90.jpg', rot90(img).permute(1,2,0).detach().cpu().numpy() * 255.)\n",
    "cv2.imwrite('./figures/airplain/flip.jpg', flip(img).permute(1,2,0).detach().cpu().numpy() * 255.)\n",
    "cv2.imwrite('./figures/airplain/random_crop.jpg', random_crop(img).permute(1,2,0).detach().cpu().numpy() * 255.)\n",
    "cv2.imwrite('./figures/airplain/gaussian_noise.jpg', np.uint8(gaussian_noise(PIL.Image.fromarray((img.permute(1,2,0).detach().cpu().numpy() * 255.).astype(np.uint8)))))\n",
    "cv2.imwrite('./figures/airplain/glass_blur.jpg', np.uint8(glass_blur(PIL.Image.fromarray((img.permute(1,2,0).detach().cpu().numpy() * 255.).astype(np.uint8)))))\n",
    "cv2.imwrite('./figures/airplain/jpeg_compression.jpg', np.uint8(jpeg_compression(PIL.Image.fromarray((img.permute(1,2,0).detach().cpu().numpy() * 255.).astype(np.uint8)))))\n",
    "cv2.imwrite('./figures/airplain/snow.jpg', np.uint8(snow(PIL.Image.fromarray((img.permute(1,2,0).detach().cpu().numpy() * 255.).astype(np.uint8)))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
