{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import torch\n",
    "import argparse\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from model import ResNet18, ResNet34, ResNet50\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "\n",
    "class load_np_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs_path, targets_path, transform):\n",
    "        self.data = np.load(imgs_path)\n",
    "        self.targets = np.load(targets_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img , targets = self.data[idx], self.targets[idx]\n",
    "            \n",
    "        img = PIL.Image.fromarray(img)\n",
    "        if transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, targets\n",
    "    \n",
    "\n",
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()\n",
    "\n",
    "\n",
    "def parsing():\n",
    "    parser = argparse.ArgumentParser(description='Tunes a CIFAR Classifier with OE',\n",
    "                                    formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('--batch_size', '-b', type=int,\n",
    "                        default=128, help='Batch size.')\n",
    "    parser.add_argument('--seed', type=int, default=1,\n",
    "                        help='seed for np(tinyimages80M sampling); 1|2|8|100|107')\n",
    "    parser.add_argument('--num_workers', type=int, \n",
    "                        default=0, help='starting epoch from.')\n",
    "    parser.add_argument('--model_path', type=str, \n",
    "                        default=None, help='Path to model to resume training.')\n",
    "    parser.add_argument('--device', type=str, \n",
    "                        default=\"cuda\", help='cuda or cpu.')\n",
    "    parser.add_argument('--aug', default='gaussian_noise', type=str, help='which aug to be run')\n",
    "    parser.add_argument('--transform', default=0, type=int, help='is augmentation a transformation or noise')\n",
    "    parser.add_argument('--run_index', default=0, type=int, help='run index')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def test(loader, net, criterion, device):\n",
    "\n",
    "    # print(\"Evaluating...\")\n",
    "    net = net.to(device)\n",
    "    net.eval()  # enter train mode\n",
    "\n",
    "    # track train classification accuracy\n",
    "    eval_acc = []\n",
    "    eval_loss = []\n",
    "    with torch.no_grad():\n",
    "        # for inputs, targets in tqdm(loader):\n",
    "        for inputs, targets in loader:\n",
    "            \n",
    "            inputs , targets = inputs.to(device) , targets.to(device)\n",
    "\n",
    "            preds = net(inputs)\n",
    "            probs = torch.softmax(preds, dim=1)\n",
    "\n",
    "            loss = criterion(preds, targets)\n",
    "            \n",
    "            output_index = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            acc = accuracy_score(list(to_np(output_index)), list(to_np(targets)))\n",
    "            eval_acc.append(acc)\n",
    "            eval_loss.append(loss.item())\n",
    "\n",
    "\n",
    "    return eval_loss, eval_acc\n",
    "\n",
    "\n",
    "def load_model(args):\n",
    "\n",
    "    # model = torchvision.models.resnet34()\n",
    "    model = ResNet18(10)\n",
    "    model.load_state_dict(torch.load(args.model_path))\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(args.device)\n",
    "\n",
    "    return model, criterion\n",
    "\n",
    "\n",
    "def load_cifar10(cifar10_path):\n",
    "\n",
    "    mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "    std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "\n",
    "    train_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "    test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "\n",
    "    train_data = torchvision.datasets.CIFAR10(\n",
    "        cifar10_path, train=True, transform=train_transform, download=True)\n",
    "    test_data = torchvision.datasets.CIFAR10(\n",
    "        cifar10_path, train=False, transform=test_transform, download=True)\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def get_subclass_dataset(dataset, classes):\n",
    "    if not isinstance(classes, list):\n",
    "        classes = [classes]\n",
    "\n",
    "    indices = []\n",
    "    for idx, tgt in enumerate(dataset.targets):\n",
    "        if tgt in classes:\n",
    "            indices.append(idx)\n",
    "\n",
    "    dataset = torch.utils.data.dataset.Subset(dataset, indices)\n",
    "\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.argv = [\"\", \"--model_path\", \"./run/best_params.pt\"]\n",
    "args = parsing()\n",
    "torch.manual_seed(args.seed)\n",
    "model, criterion = load_model(args)\n",
    "\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "\n",
    "cifar10_path = '/storage/users/makhavan/CSI/finals/datasets/data/'\n",
    "test_dataset = torchvision.datasets.CIFAR10(cifar10_path, train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=args.batch_size, num_workers=args.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss_cifar10, eval_acc_cifar10 = test(test_loader, model, criterion, args.device)\n",
    "print(\"loss:\", np.mean(eval_loss_cifar10),\"acc:\", np.mean(eval_acc_cifar10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test2(loader, net, criterion, device):\n",
    "\n",
    "    # print(\"Evaluating...\")\n",
    "    net = net.to(device)\n",
    "    net.eval()  # enter train mode\n",
    "\n",
    "    # track train classification accuracy\n",
    "    eval_acc = []\n",
    "    eval_loss = []\n",
    "    with torch.no_grad():\n",
    "        # for inputs, targets in tqdm(loader):\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs + (1/255)\n",
    "            inputs , targets = inputs.to(device) , targets.to(device)\n",
    "\n",
    "            preds = net(inputs)\n",
    "            probs = torch.softmax(preds, dim=1)\n",
    "\n",
    "            loss = criterion(preds, targets)\n",
    "            \n",
    "            output_index = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            acc = accuracy_score(list(to_np(output_index)), list(to_np(targets)))\n",
    "            eval_acc.append(acc)\n",
    "            eval_loss.append(loss.item())\n",
    "\n",
    "\n",
    "    return eval_loss, eval_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss_cifar10, eval_acc_cifar10 = test2(test_loader, model, criterion, args.device)\n",
    "print(\"loss:\", np.mean(eval_loss_cifar10),\"acc:\", np.mean(eval_acc_cifar10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ResNet18, ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# img = torch.rand((1,3,56,56))\n",
    "img = torch.rand((64,3,32,32))\n",
    "output, feature_list = model(img, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 512, 4, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
